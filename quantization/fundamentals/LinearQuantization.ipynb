{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize and Dequantiza a Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_q_with_scale_and_zero_point(\n",
    "    tensor,\n",
    "    scale,\n",
    "    zero_point,\n",
    "    dtype=torch.int8\n",
    "):\n",
    "    scaled_and_shifted_tensor = tensor / scale + zero_point\n",
    "    rounded_tensor = torch.round(scaled_and_shifted_tensor)\n",
    "    \n",
    "    # make sure the value is between min and max quantize value\n",
    "    q_min = torch.iinfo(dtype).min\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "    \n",
    "    q_tensor = rounded_tensor.clamp(q_min, q_max).to(dtype)\n",
    "    return q_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.tensor(\n",
    "    [[191.6, -13.5, 728.6],\n",
    "     [92.14, 295.5, -184],\n",
    "     [0,     684.6, 245.5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcoded scale and zero point\n",
    "scale = 3.5\n",
    "zero_point = -70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor = linear_q_with_scale_and_zero_point(test_tensor,\n",
    "    scale, zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -15,  -74,  127],\n",
       "        [ -44,   14, -123],\n",
       "        [ -70,  126,    0]], dtype=torch.int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_tensor = scale * (quantized_tensor.float() - zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 192.5000,  -14.0000,  689.5000],\n",
       "        [  91.0000,  294.0000, -185.5000],\n",
       "        [   0.0000,  686.0000,  245.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 192.5000,  -14.0000, -206.5000],\n",
       "        [  91.0000,  294.0000, -185.5000],\n",
       "        [   0.0000, -210.0000,  245.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problems if not casting to float\n",
    "scale * (quantized_tensor - zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_dequantization(q, scale, zero_point):\n",
    "    return scale * (q.float() - zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(170.8753)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quantization error\n",
    "(dequantized_tensor - test_tensor).square().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate scale and zero point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-128 127\n"
     ]
    }
   ],
   "source": [
    "q_min = torch.iinfo(torch.int8).min\n",
    "q_max = torch.iinfo(torch.int8).max\n",
    "\n",
    "print(q_min, q_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-184.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_min = test_tensor.min().item()\n",
    "r_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728.5999755859375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_max = test_tensor.max().item()\n",
    "r_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.578823433670343"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = (r_max-r_min)/(q_max-q_min)\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-77"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_point = int(round(q_min - (r_min/scale)))\n",
    "zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_scale_and_zero_point(tensor, dtype=torch.int8):\n",
    "    q_min = torch.iinfo(torch.int8).min\n",
    "    q_max = torch.iinfo(torch.int8).max\n",
    "    r_min = tensor.min().item()\n",
    "    r_max = tensor.max().item()\n",
    "    \n",
    "    scale = (r_max-r_min)/(q_max-q_min)\n",
    "    zero_point = q_min - (r_min/scale)\n",
    "    \n",
    "    if zero_point < q_min:\n",
    "        zero_point = q_min\n",
    "    elif zero_point > q_max:\n",
    "        zero_point = q_max\n",
    "    else: zero_point = int(round(zero_point))\n",
    "    \n",
    "    return scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.578823433670343 -77\n"
     ]
    }
   ],
   "source": [
    "new_scale, new_zero_point = get_q_scale_and_zero_point(test_tensor)\n",
    "print(new_scale, new_zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor = linear_q_with_scale_and_zero_point(test_tensor,\n",
    "        new_scale, new_zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_tensor = linear_dequantization(quantized_tensor, new_scale,\n",
    "                                            new_zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5730)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dequantized_tensor - test_tensor).square().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_quantization(tensor, dtype=torch.int8):\n",
    "    scale, zero_point = get_q_scale_and_zero_point(tensor, dtype=dtype)\n",
    "    quantized_tensor = linear_q_with_scale_and_zero_point(tensor,\n",
    "            scale, zero_point, dtype=dtype)\n",
    "    \n",
    "    return quantized_tensor, scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8507, -0.2863, -0.0977, -0.6233],\n",
       "        [-0.4456,  0.1131,  1.0762,  0.6507],\n",
       "        [ 0.3937, -0.5725,  0.2385, -1.1075],\n",
       "        [-1.4498,  1.4015,  0.9169,  1.2282]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_tensor = torch.randn((4, 4))\n",
    "r_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor, scale, zero_point = linear_quantization(r_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -74,  -24,   -7,  -54],\n",
       "         [ -38,   12,   98,   60],\n",
       "         [  37,  -49,   23,  -97],\n",
       "         [-128,  127,   84,  112]], dtype=torch.int8),\n",
       " 0.011181414828580968,\n",
       " 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_tensor, scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8498, -0.2907, -0.1006, -0.6262],\n",
       "        [-0.4473,  0.1118,  1.0734,  0.6485],\n",
       "        [ 0.3913, -0.5703,  0.2348, -1.1070],\n",
       "        [-1.4536,  1.3977,  0.9169,  1.2300]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequantized_tensor = linear_dequantization(quantized_tensor, scale, zero_point)\n",
    "dequantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9450e-06)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dequantized_tensor - r_tensor).square().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetric mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_scale_symmetric(tensor, dtype=torch.int8):\n",
    "    r_max = tensor.abs().max().item()\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "    \n",
    "    return r_max / q_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7235,  0.4838,  0.1597,  1.2745],\n",
       "        [-0.3974,  0.0629, -1.5674, -0.4455],\n",
       "        [ 1.3539,  1.3741,  0.8218, -1.8537],\n",
       "        [ 0.3220, -1.9573,  0.9014,  0.7699]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.randn((4, 4))\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015412120368537001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_q_scale_symmetric(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_q_symmetric(tensor, dtype=torch.int8):\n",
    "    scale = get_q_scale_symmetric(tensor)\n",
    "    quantized_tensor = linear_q_with_scale_and_zero_point(tensor, scale,\n",
    "        zero_point=0, dtype=dtype)\n",
    "    return quantized_tensor, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor, scale = linear_q_symmetric(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_tensor = linear_dequantization(quantized_tensor, scale, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5442274161614478e-05"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dequantized_tensor - test_tensor).square().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per channel quantization with symmetric mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.tensor([\n",
    "    [191.6, -13.5, 728.6],\n",
    "    [92.14, 295.5, -184],\n",
    "    [0,     684.6, 245.5]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 0\n",
    "output_dim = test_tensor.shape[dim]\n",
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = torch.zeros(output_dim)\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(output_dim):\n",
    "    sub_tensor = test_tensor.select(dim, index)\n",
    "    scale[index] = get_q_scale_symmetric(sub_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.7370, 2.3268, 5.3906])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_shape = [1] * test_tensor.dim()\n",
    "scale_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_shape[dim] = -1\n",
    "scale_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.7370],\n",
       "        [2.3268],\n",
       "        [5.3906]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = scale.view(scale_shape)\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 33,  -2, 127],\n",
       "        [ 40, 127, -79],\n",
       "        [  0, 127,  46]], dtype=torch.int8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_tensor = linear_q_with_scale_and_zero_point(test_tensor,\n",
    "                            scale=scale, zero_point=0)\n",
    "quantized_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge everything above in 1 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_q_symmetric_per_channel(tensor, dim, dtype=torch.int8):\n",
    "    output_dim = tensor.shape[dim]\n",
    "    scale = torch.zeros(output_dim)\n",
    "    \n",
    "    for index in range(output_dim):\n",
    "        sub_tensor = tensor.select(dim, index)\n",
    "        scale[index] = get_q_scale_symmetric(sub_tensor)\n",
    "        \n",
    "    # reshape scale\n",
    "    scale_shape = [1] * tensor.dim()\n",
    "    scale_shape[dim] = -1\n",
    "    scale = scale.view(scale_shape)\n",
    "    \n",
    "    quantized_tensor = linear_q_with_scale_and_zero_point(\n",
    "        tensor, scale=scale, zero_point=0, dtype=dtype\n",
    "    )\n",
    "\n",
    "    return quantized_tensor, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor_0, scale_0 = linear_q_symmetric_per_channel(\n",
    "    test_tensor, dim=0\n",
    ")\n",
    "quantized_tensor_1, scale_1 = linear_q_symmetric_per_channel(\n",
    "    test_tensor, dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8084441423416138"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequantized_tensor_0 = linear_dequantization(quantized_tensor_0, scale_0, 0)\n",
    "(dequantized_tensor_0 - test_tensor).square().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0781488418579102"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequantized_tensor_1 = linear_dequantization(quantized_tensor_1, scale_1, 0)\n",
    "(dequantized_tensor_1 - test_tensor).square().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per group quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_q_symmetric_per_group(tensor, group_size, dtype=torch.int8):\n",
    "    t_shape = tensor.shape\n",
    "    assert t_shape[1] % group_size == 0\n",
    "    assert tensor.dim() == 2\n",
    "    \n",
    "    tensor = tensor.view(-1, group_size)\n",
    "    quantized_tensor, scale = linear_q_symmetric_per_channel(\n",
    "        tensor, dim=0, dtype=dtype\n",
    "    )\n",
    "    quantized_tensor = quantized_tensor.view(t_shape)\n",
    "    return quantized_tensor, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_dequantization_per_group(\n",
    "    quantized_tensor, scale, group_size\n",
    "):\n",
    "    q_shape = quantized_tensor.shape\n",
    "    quantized_tensor = quantized_tensor.view(-1, group_size)\n",
    "    dequantized_tensor = linear_dequantization(quantized_tensor, scale, 0)\n",
    "    dequantized_tensor = dequantized_tensor.view(q_shape)\n",
    "    \n",
    "    return dequantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.rand((6, 6))\n",
    "group_size = 3\n",
    "quantized_tensor, scale = linear_q_symmetric_per_group(\n",
    "    test_tensor, group_size=group_size\n",
    ")\n",
    "dequantized_tensor = linear_dequantization_per_group(quantized_tensor, scale, group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.218512008766993e-06"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dequantized_tensor - test_tensor).square().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Linear Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights to 8 bits, activations remains in 32 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_linear_W8A32_without_bias(input, q_w, s_w, z_w):\n",
    "    assert input.dtype == torch.float32\n",
    "    assert q_w.dtype == torch.int8\n",
    "    \n",
    "    dequantized_weight = q_w.to(torch.float32) * s_w + z_w\n",
    "    output = torch.nn.functional.linear(input, dequantized_weight)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([1, 2, 3], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor([\n",
    "    [-2, -1.13, 0.42],\n",
    "    [-1.51, 0.25, 1.62],\n",
    "    [0.23, 1.35, 2.15]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-118,  -67,   25],\n",
       "         [ -89,   15,   96],\n",
       "         [  14,   80,  127]], dtype=torch.int8),\n",
       " 0.016929134609192376)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_w, s_w = linear_q_symmetric(weight)\n",
    "q_w, s_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.9965,  3.8768,  9.3957])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = quantized_linear_W8A32_without_bias(input, q_w, s_w, 0)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.0000,  3.8500,  9.3800])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f32_output = torch.nn.functional.linear(input, weight)\n",
    "f32_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
